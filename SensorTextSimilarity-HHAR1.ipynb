{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959de12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "EMBEDDING_DIM = 64     \n",
    "MARGIN = 0.5           \n",
    "EPOCHS = 30            \n",
    "BATCH_SIZE = 4         \n",
    "LEARNING_RATE = 1e-4   \n",
    "TEXT_MODEL_NAME = \"distilbert-base-uncased\" \n",
    "\n",
    "# --- HHAR CONFIGURATION ---\n",
    "SENSOR_FEATURES_COUNT = 6 # Acc_x, Acc_y, Acc_z, Gyro_X, Gyro_Y, Gyro_Z\n",
    "TEXT_COLUMN_NAME = 'Semantic_Interpretation'\n",
    "SENSOR_COLUMNS = ['Acc_x', 'Acc_y', 'Acc_z', 'Gyro_X', 'Gyro_Y', 'Gyro_Z']\n",
    "SENSOR_MODEL_PATH = 'sensor_encoder_hhar_6col.pth'\n",
    "TEXT_MODEL_PATH = 'text_encoder_hhar_6col.pth'\n",
    "DATA_FILE = \"HHAR_semantic_interpretation.csv\" \n",
    "\n",
    "# --- 2. DATASET CLASS ---\n",
    "\n",
    "class SensorTextDataset(Dataset):\n",
    "    def __init__(self, sensor_data, text_data, labels):\n",
    "        self.sensor_data = torch.tensor(sensor_data, dtype=torch.float32)\n",
    "        self.text_data = text_data\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sensor_data[idx], self.text_data[idx], self.labels[idx]\n",
    "\n",
    "# --- 3. DUAL-ENCODER ARCHITECTURE ---\n",
    "\n",
    "class SensorEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name, output_dim):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.projection = nn.Linear(self.model.config.hidden_size, output_dim)\n",
    "    def forward(self, texts):\n",
    "        if isinstance(texts, torch.Tensor):\n",
    "             texts = texts.tolist()\n",
    "             \n",
    "        encoded_input = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        device = self.projection.weight.device\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        \n",
    "        output = self.model(**encoded_input)\n",
    "        mean_pooled = torch.mean(output.last_hidden_state, dim=1)\n",
    "        return self.projection(mean_pooled)\n",
    "\n",
    "# --- 4. CONTRASTIVE LOSS FUNCTION (Cosine Similarity) ---\n",
    "\n",
    "class ContrastiveSimilarityLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(ContrastiveSimilarityLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        similarity = F.cosine_similarity(output1, output2).unsqueeze(1)\n",
    "        \n",
    "        device = output1.device\n",
    "        zero_tensor = torch.tensor(0.0).to(device)\n",
    "        margin_tensor = torch.tensor(self.margin).to(device)\n",
    "\n",
    "        loss_positive = label * (1 - similarity)\n",
    "        loss_negative = (1 - label) * torch.max(zero_tensor, similarity - margin_tensor)\n",
    "        \n",
    "        loss = torch.mean(loss_positive + loss_negative)\n",
    "        return loss\n",
    "\n",
    "# --- 5. TRAINING FUNCTION ---\n",
    "\n",
    "def train_contrastive_model():\n",
    "    print(\"--- Starting Training (Cosine Similarity Contrastive Loss) ---\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    \n",
    "    sensor_cols = SENSOR_COLUMNS \n",
    "\n",
    "    if set(sensor_cols).issubset(df.columns) is False:\n",
    "        raise ValueError(f\"Required sensor columns {sensor_cols} not found in {DATA_FILE}\")\n",
    "\n",
    "    if len(sensor_cols) != SENSOR_FEATURES_COUNT:\n",
    "        raise ValueError(f\"Feature count mismatch! Expected {SENSOR_FEATURES_COUNT} features, but detected {len(sensor_cols)} in the data file: {DATA_FILE}\")\n",
    "\n",
    "    sensor_data = df[sensor_cols].values\n",
    "    text_data = df[TEXT_COLUMN_NAME].tolist()\n",
    "\n",
    "    # Create POSITIVE and NEGATIVE training samples\n",
    "    pos_sensor, pos_text, pos_labels = sensor_data, text_data, np.ones(len(df))\n",
    "    neg_sensor = sensor_data\n",
    "    neg_text = np.roll(text_data, 1).tolist()\n",
    "    neg_labels = np.zeros(len(df))\n",
    "\n",
    "    all_sensor = np.concatenate([pos_sensor, neg_sensor])\n",
    "    all_text = pos_text + neg_text\n",
    "    all_labels = np.concatenate([pos_labels, neg_labels])\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train_s, X_test_s, X_train_t, X_test_t, y_train, y_test = train_test_split(\n",
    "        all_sensor, all_text, all_labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    sensor_encoder = SensorEncoder(SENSOR_FEATURES_COUNT, EMBEDDING_DIM).to(device)\n",
    "    text_encoder = TextEncoder(TEXT_MODEL_NAME, EMBEDDING_DIM).to(device)\n",
    "    criterion = ContrastiveSimilarityLoss(margin=MARGIN)\n",
    "    \n",
    "    params = list(sensor_encoder.parameters()) + list(text_encoder.parameters())\n",
    "    optimizer = optim.Adam(params, lr=LEARNING_RATE)\n",
    "\n",
    "    train_dataset = SensorTextDataset(X_train_s, X_train_t, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(f\"Total training pairs: {len(train_dataset)}\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        sensor_encoder.train()\n",
    "        text_encoder.train()\n",
    "        \n",
    "        for sensor_batch, text_batch, label_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            sensor_batch = sensor_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            \n",
    "            sensor_embedding = sensor_encoder(sensor_batch)\n",
    "            text_embedding = text_encoder(text_batch)\n",
    "            \n",
    "            loss = criterion(sensor_embedding, text_embedding, label_batch.unsqueeze(1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"\\nTraining complete.\")\n",
    "    \n",
    "    torch.save(sensor_encoder.state_dict(), SENSOR_MODEL_PATH)\n",
    "    torch.save(text_encoder.state_dict(), TEXT_MODEL_PATH)\n",
    "    print(f\"Models saved: {SENSOR_MODEL_PATH} and {TEXT_MODEL_PATH}\")\n",
    "\n",
    "    return X_test_s, X_test_t, y_test\n",
    "\n",
    "# --- 6. EVALUATION FUNCTION ---\n",
    "\n",
    "def evaluate_contrastive_model(X_test_s, X_test_t, y_test):\n",
    "    print(\"\\n--- Starting Evaluation on Test Data ---\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    sensor_encoder = SensorEncoder(SENSOR_FEATURES_COUNT, EMBEDDING_DIM).to(device)\n",
    "    text_encoder = TextEncoder(TEXT_MODEL_NAME, EMBEDDING_DIM).to(device)\n",
    "\n",
    "    try:\n",
    "        sensor_encoder.load_state_dict(torch.load(SENSOR_MODEL_PATH, map_location=device))\n",
    "        text_encoder.load_state_dict(torch.load(TEXT_MODEL_PATH, map_location=device))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model files not found. Please ensure {SENSOR_MODEL_PATH} and {TEXT_MODEL_PATH} exist.\")\n",
    "        return\n",
    "\n",
    "    sensor_encoder.eval()\n",
    "    text_encoder.eval()\n",
    "    \n",
    "    test_dataset = SensorTextDataset(X_test_s, X_test_t, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    similarities = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sensor_batch, text_batch, label_batch in test_loader:\n",
    "            sensor_batch = sensor_batch.to(device)\n",
    "            \n",
    "            sensor_embedding = sensor_encoder(sensor_batch)\n",
    "            text_embedding = text_encoder(text_batch)\n",
    "            \n",
    "            sim = F.cosine_similarity(sensor_embedding, text_embedding)\n",
    "            similarities.extend(sim.cpu().numpy())\n",
    "            true_labels.extend(label_batch.cpu().numpy())\n",
    "\n",
    "    similarities = np.array(similarities)\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    pos_similarities = similarities[true_labels == 1.0]\n",
    "    neg_similarities = similarities[true_labels == 0.0]\n",
    "\n",
    "    print(f\"Test Set Size: {len(true_labels)}\")\n",
    "    print(f\"Mean Similarity (Positive Pairs): {np.mean(pos_similarities):.4f}\")\n",
    "    print(f\"Mean Similarity (Negative Pairs): {np.mean(neg_similarities):.4f}\")\n",
    "    \n",
    "    predictions = (similarities > MARGIN).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Matching Accuracy (Similarity > MARGIN={MARGIN}): {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        X_test_s, X_test_t, y_test = train_contrastive_model()\n",
    "        evaluate_contrastive_model(X_test_s, X_test_t, y_test)\n",
    "    except Exception as e:\n",
    "        # Final reminder for the user to address the environment error locally.\n",
    "        print(\"\\n----------------------------------------------------------------------\")\n",
    "        print(\"ðŸ›‘ **EXECUTION REMINDER** ðŸ›‘\")\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"\\n**ACTION REQUIRED:** This persistent error is due to a misconfigured PyTorch installation in your current environment. Please follow the steps above (Clean Up, Create New Env, Reinstall Libraries) to fix your local setup, then run this code again.\")\n",
    "        print(\"----------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
