{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9e424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "[WARN] Could not load sensor state_dict cleanly: Error(s) in loading state_dict for SensorEncoder:\n",
      "\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([128, 14]) from checkpoint, the shape in current model is torch.Size([128, 6]).. Using fresh sensor encoder.\n",
      "[INFO] Using HuggingFace transformers for TextEncoder.\n",
      "[INFO] Loaded text encoder projection weights (strict=False).\n",
      "-------------------------------------------------------------\n",
      "ATTACK SAMPLE index=0 activity=Stress\n",
      "text preview: '**General description:** Non‑stress periods display relaxed autonomic balance and smoother movement control.\n",
      "**Accelerom...'\n",
      "-------------------------------------------------------------\n",
      "[attack] step 1/1000 loss=0.787763 sim=0.205347 linfΔ=0.495171 ‖∇‖=4.052399e-01\n",
      "[attack] step 1/1000 loss=0.551056 sim=0.443607 linfΔ=0.496124 ‖∇‖=3.230856e-01\n",
      "[attack] step 1/1000 loss=0.946168 sim=0.046258 linfΔ=0.483051 ‖∇‖=4.542835e-01\n",
      "EPS=0.5  orig_sim=0.8516 adv_sim=0.0463 loss_before=0.148418 loss_after=0.953742 linf=0.483051 l2=2.259675 success=1 note=\n",
      "[attack] step 1/1000 loss=0.620292 sim=0.373359 linfΔ=0.600000 ‖∇‖=3.144231e-01\n",
      "[attack] step 1/1000 loss=0.674263 sim=0.319650 linfΔ=0.583284 ‖∇‖=3.036740e-01\n",
      "[attack] step 1/1000 loss=0.643086 sim=0.350442 linfΔ=0.580305 ‖∇‖=3.196831e-01\n",
      "EPS=0.6  orig_sim=0.8516 adv_sim=0.3196 loss_before=0.148418 loss_after=0.680350 linf=0.583284 l2=2.760926 success=1 note=\n",
      "[attack] step 1/1000 loss=0.912304 sim=0.080951 linfΔ=0.700000 ‖∇‖=2.929036e-01\n",
      "[attack] step 1/1000 loss=0.761660 sim=0.232162 linfΔ=0.695688 ‖∇‖=2.638304e-01\n",
      "[attack] step 1/1000 loss=0.765104 sim=0.228415 linfΔ=0.686046 ‖∇‖=2.791421e-01\n",
      "EPS=0.7  orig_sim=0.8516 adv_sim=0.0810 loss_before=0.148418 loss_after=0.919050 linf=0.700000 l2=3.341018 success=1 note=\n",
      "[attack] step 1/1000 loss=0.750590 sim=0.243369 linfΔ=0.781398 ‖∇‖=2.327531e-01\n",
      "[attack] step 1/1000 loss=0.722957 sim=0.270345 linfΔ=0.783637 ‖∇‖=2.546000e-01\n",
      "[attack] step 1/1000 loss=0.776659 sim=0.216384 linfΔ=0.787268 ‖∇‖=2.663129e-01\n",
      "EPS=0.8  orig_sim=0.8516 adv_sim=0.2164 loss_before=0.148418 loss_after=0.783616 linf=0.787268 l2=3.554041 success=1 note=\n",
      "[attack] step 1/1000 loss=0.808745 sim=0.184411 linfΔ=0.878292 ‖∇‖=2.274743e-01\n",
      "[attack] step 1/1000 loss=0.819076 sim=0.174181 linfΔ=0.886092 ‖∇‖=2.261257e-01\n",
      "[attack] step 1/1000 loss=0.900406 sim=0.092394 linfΔ=0.882515 ‖∇‖=2.361482e-01\n",
      "EPS=0.9  orig_sim=0.8516 adv_sim=0.0924 loss_before=0.148418 loss_after=0.907606 linf=0.882515 l2=4.170307 success=1 note=\n",
      "[attack] step 1/1000 loss=0.909640 sim=0.083123 linfΔ=1.000000 ‖∇‖=2.222835e-01\n",
      "[attack] step 1/1000 loss=0.728817 sim=0.264142 linfΔ=0.974209 ‖∇‖=2.102814e-01\n",
      "[attack] step 1/1000 loss=0.803333 sim=0.189776 linfΔ=0.987401 ‖∇‖=2.059645e-01\n",
      "EPS=1  orig_sim=0.8516 adv_sim=0.0831 loss_before=0.148418 loss_after=0.916877 linf=1.000000 l2=4.478203 success=1 note=\n",
      "[attack] step 1/1000 loss=0.768169 sim=0.225087 linfΔ=2.000000 ‖∇‖=9.936005e-02\n",
      "[attack] step 1/1000 loss=0.826926 sim=0.166213 linfΔ=1.986854 ‖∇‖=1.046046e-01\n",
      "[attack] step 1/1000 loss=0.893475 sim=0.099253 linfΔ=1.980078 ‖∇‖=1.080860e-01\n",
      "EPS=2  orig_sim=0.8516 adv_sim=0.0993 loss_before=0.148418 loss_after=0.900747 linf=1.980078 l2=9.142859 success=1 note=\n",
      "[attack] step 1/1000 loss=0.847517 sim=0.145457 linfΔ=2.956144 ‖∇‖=7.092832e-02\n",
      "[attack] step 1/1000 loss=0.747562 sim=0.245596 linfΔ=2.957479 ‖∇‖=6.912102e-02\n",
      "[attack] step 1/1000 loss=0.714040 sim=0.279393 linfΔ=2.919393 ‖∇‖=6.616195e-02\n",
      "EPS=3  orig_sim=0.8516 adv_sim=0.1455 loss_before=0.148418 loss_after=0.854543 linf=2.956144 l2=13.885418 success=1 note=\n",
      "[attack] step 1/1000 loss=0.838464 sim=0.154044 linfΔ=3.980116 ‖∇‖=5.467961e-02\n",
      "[attack] step 1/1000 loss=1.194787 sim=-0.201747 linfΔ=3.852439 ‖∇‖=5.263815e-02\n",
      "[attack] step 1/1000 loss=1.038791 sim=-0.046326 linfΔ=3.995442 ‖∇‖=5.681036e-02\n",
      "EPS=4  orig_sim=0.8516 adv_sim=-0.2017 loss_before=0.148418 loss_after=1.201747 linf=3.852439 l2=18.826715 success=1 note=\n",
      "[attack] step 1/1000 loss=1.106946 sim=-0.114515 linfΔ=4.854648 ‖∇‖=4.530640e-02\n",
      "[attack] step 1/1000 loss=1.063359 sim=-0.070838 linfΔ=4.883396 ‖∇‖=4.476312e-02\n",
      "[attack] step 1/1000 loss=0.966908 sim=0.026262 linfΔ=4.965944 ‖∇‖=4.082526e-02\n",
      "EPS=5  orig_sim=0.8516 adv_sim=-0.1145 loss_before=0.148418 loss_after=1.114515 linf=4.854648 l2=21.975140 success=1 note=\n",
      "[attack] step 1/1000 loss=0.996062 sim=-0.003536 linfΔ=5.791757 ‖∇‖=3.722814e-02\n",
      "[attack] step 1/1000 loss=1.050974 sim=-0.057914 linfΔ=5.986468 ‖∇‖=3.441866e-02\n",
      "[attack] step 1/1000 loss=0.779859 sim=0.213031 linfΔ=5.920446 ‖∇‖=3.550153e-02\n",
      "EPS=6  orig_sim=0.8516 adv_sim=-0.0579 loss_before=0.148418 loss_after=1.057914 linf=5.986468 l2=29.123537 success=1 note=\n",
      "[attack] step 1/1000 loss=0.957387 sim=0.036422 linfΔ=6.957696 ‖∇‖=2.641567e-02\n",
      "[attack] step 1/1000 loss=1.067660 sim=-0.076091 linfΔ=6.836805 ‖∇‖=3.573970e-02\n",
      "[attack] step 1/1000 loss=0.881018 sim=0.111756 linfΔ=6.968490 ‖∇‖=3.056270e-02\n",
      "EPS=7  orig_sim=0.8516 adv_sim=-0.0761 loss_before=0.148418 loss_after=1.076091 linf=6.836805 l2=27.996782 success=1 note=\n",
      "[attack] step 1/1000 loss=0.939957 sim=0.051890 linfΔ=7.683760 ‖∇‖=3.042712e-02\n",
      "[attack] step 1/1000 loss=0.879643 sim=0.112522 linfΔ=8.000000 ‖∇‖=2.934570e-02\n",
      "[attack] step 1/1000 loss=1.051607 sim=-0.058414 linfΔ=7.983735 ‖∇‖=2.547064e-02\n",
      "EPS=8  orig_sim=0.8516 adv_sim=-0.0584 loss_before=0.148418 loss_after=1.058414 linf=7.983735 l2=39.311234 success=1 note=\n",
      "[attack] step 1/1000 loss=0.867499 sim=0.125501 linfΔ=8.877905 ‖∇‖=2.338979e-02\n",
      "[attack] step 1/1000 loss=0.955527 sim=0.035963 linfΔ=8.779599 ‖∇‖=2.818298e-02\n",
      "[attack] step 1/1000 loss=0.953569 sim=0.039195 linfΔ=8.967794 ‖∇‖=2.406170e-02\n",
      "EPS=9  orig_sim=0.8516 adv_sim=0.0360 loss_before=0.148418 loss_after=0.964037 linf=8.779599 l2=35.429161 success=1 note=\n",
      "[attack] step 1/1000 loss=1.033880 sim=-0.041636 linfΔ=9.514978 ‖∇‖=2.321997e-02\n",
      "[attack] step 1/1000 loss=0.872209 sim=0.121057 linfΔ=9.821262 ‖∇‖=2.007094e-02\n",
      "[attack] step 1/1000 loss=0.848806 sim=0.143968 linfΔ=10.000000 ‖∇‖=2.151761e-02\n",
      "EPS=10  orig_sim=0.8516 adv_sim=-0.0416 loss_before=0.148418 loss_after=1.041636 linf=9.514978 l2=43.110340 success=1 note=\n",
      "-------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------\n",
      "ATTACK SAMPLE index=4000 activity=not\n",
      "text preview: '**General description:** Non‑stress periods display relaxed autonomic balance and smoother movement control.\n",
      "**Accelerom...'\n",
      "-------------------------------------------------------------\n",
      "[attack] step 1/1000 loss=0.603228 sim=0.391272 linfΔ=0.500000 ‖∇‖=3.361267e-01\n",
      "[attack] step 1/1000 loss=0.753874 sim=0.239693 linfΔ=0.483756 ‖∇‖=3.871131e-01\n",
      "[attack] step 1/1000 loss=0.838775 sim=0.153515 linfΔ=0.489604 ‖∇‖=4.605897e-01\n",
      "EPS=0.5  orig_sim=0.8251 adv_sim=0.1535 loss_before=0.174931 loss_after=0.846485 linf=0.489604 l2=2.119612 success=1 note=\n",
      "[attack] step 1/1000 loss=0.710337 sim=0.282889 linfΔ=0.575728 ‖∇‖=3.272825e-01\n",
      "[attack] step 1/1000 loss=0.716192 sim=0.277396 linfΔ=0.600000 ‖∇‖=3.343242e-01\n",
      "[attack] step 1/1000 loss=0.633007 sim=0.360418 linfΔ=0.593542 ‖∇‖=3.183325e-01\n",
      "EPS=0.6  orig_sim=0.8251 adv_sim=0.2774 loss_before=0.174931 loss_after=0.722604 linf=0.600000 l2=2.737216 success=1 note=\n",
      "[attack] step 1/1000 loss=1.055222 sim=-0.062594 linfΔ=0.696050 ‖∇‖=3.119726e-01\n",
      "[attack] step 1/1000 loss=0.867901 sim=0.124849 linfΔ=0.694129 ‖∇‖=3.051497e-01\n",
      "[attack] step 1/1000 loss=0.755252 sim=0.237559 linfΔ=0.673645 ‖∇‖=3.152589e-01\n",
      "EPS=0.7  orig_sim=0.8251 adv_sim=-0.0626 loss_before=0.174931 loss_after=1.062593 linf=0.696050 l2=3.231104 success=1 note=\n",
      "[attack] step 1/1000 loss=0.935923 sim=0.056598 linfΔ=0.787887 ‖∇‖=2.810292e-01\n",
      "[attack] step 1/1000 loss=0.745068 sim=0.248396 linfΔ=0.794323 ‖∇‖=2.449557e-01\n",
      "[attack] step 1/1000 loss=0.910251 sim=0.083257 linfΔ=0.794534 ‖∇‖=2.447342e-01\n",
      "EPS=0.8  orig_sim=0.8251 adv_sim=0.0566 loss_before=0.174931 loss_after=0.943402 linf=0.787887 l2=3.559178 success=1 note=\n",
      "[attack] step 1/1000 loss=0.772620 sim=0.220798 linfΔ=0.900000 ‖∇‖=2.182519e-01\n",
      "[attack] step 1/1000 loss=0.807823 sim=0.185263 linfΔ=0.883957 ‖∇‖=2.325099e-01\n",
      "[attack] step 1/1000 loss=0.739406 sim=0.253684 linfΔ=0.897532 ‖∇‖=2.275917e-01\n",
      "EPS=0.9  orig_sim=0.8251 adv_sim=0.1853 loss_before=0.174931 loss_after=0.814737 linf=0.883957 l2=4.133410 success=1 note=\n",
      "[attack] step 1/1000 loss=0.710268 sim=0.283193 linfΔ=0.961392 ‖∇‖=1.983020e-01\n",
      "[attack] step 1/1000 loss=0.906021 sim=0.087491 linfΔ=0.999438 ‖∇‖=1.936135e-01\n",
      "[attack] step 1/1000 loss=0.778026 sim=0.215286 linfΔ=0.997602 ‖∇‖=2.029390e-01\n",
      "EPS=1  orig_sim=0.8251 adv_sim=0.0875 loss_before=0.174931 loss_after=0.912509 linf=0.999438 l2=5.168147 success=1 note=\n",
      "[attack] step 1/1000 loss=1.138798 sim=-0.146291 linfΔ=1.972381 ‖∇‖=1.114758e-01\n",
      "[attack] step 1/1000 loss=0.959774 sim=0.033209 linfΔ=1.962398 ‖∇‖=1.049251e-01\n",
      "[attack] step 1/1000 loss=0.723623 sim=0.270067 linfΔ=1.994406 ‖∇‖=9.770834e-02\n",
      "EPS=2  orig_sim=0.8251 adv_sim=-0.1463 loss_before=0.174931 loss_after=1.146291 linf=1.972381 l2=9.047552 success=1 note=\n",
      "[attack] step 1/1000 loss=0.920308 sim=0.072635 linfΔ=2.946074 ‖∇‖=7.056393e-02\n",
      "[attack] step 1/1000 loss=0.825493 sim=0.167513 linfΔ=2.954885 ‖∇‖=7.025789e-02\n",
      "[attack] step 1/1000 loss=0.836377 sim=0.157110 linfΔ=2.991199 ‖∇‖=6.658515e-02\n",
      "EPS=3  orig_sim=0.8251 adv_sim=0.0726 loss_before=0.174931 loss_after=0.927365 linf=2.946074 l2=14.111917 success=1 note=\n",
      "[attack] step 1/1000 loss=0.912758 sim=0.079718 linfΔ=3.871951 ‖∇‖=5.686556e-02\n",
      "[attack] step 1/1000 loss=0.770661 sim=0.222148 linfΔ=3.985879 ‖∇‖=5.410422e-02\n",
      "[attack] step 1/1000 loss=0.879434 sim=0.112650 linfΔ=3.951642 ‖∇‖=5.915775e-02\n",
      "EPS=4  orig_sim=0.8251 adv_sim=0.0797 loss_before=0.174931 loss_after=0.920282 linf=3.871951 l2=17.483698 success=1 note=\n",
      "[attack] step 1/1000 loss=0.975625 sim=0.016889 linfΔ=4.906237 ‖∇‖=4.498654e-02\n",
      "[attack] step 1/1000 loss=0.762418 sim=0.229839 linfΔ=4.793339 ‖∇‖=4.622436e-02\n",
      "[attack] step 1/1000 loss=1.117398 sim=-0.124926 linfΔ=4.832083 ‖∇‖=4.561332e-02\n",
      "EPS=5  orig_sim=0.8251 adv_sim=-0.1249 loss_before=0.174931 loss_after=1.124926 linf=4.832083 l2=21.776333 success=1 note=\n",
      "[attack] step 1/1000 loss=0.939834 sim=0.052519 linfΔ=6.000000 ‖∇‖=3.829939e-02\n",
      "[attack] step 1/1000 loss=0.882637 sim=0.110719 linfΔ=5.735072 ‖∇‖=3.275873e-02\n",
      "[attack] step 1/1000 loss=0.943722 sim=0.049041 linfΔ=5.972905 ‖∇‖=3.595563e-02\n",
      "EPS=6  orig_sim=0.8251 adv_sim=0.0490 loss_before=0.174931 loss_after=0.950959 linf=5.972905 l2=27.840004 success=1 note=\n",
      "[attack] step 1/1000 loss=1.053060 sim=-0.059959 linfΔ=6.999596 ‖∇‖=2.991537e-02\n",
      "[attack] step 1/1000 loss=0.869309 sim=0.123326 linfΔ=7.000000 ‖∇‖=3.157666e-02\n",
      "[attack] step 1/1000 loss=1.027530 sim=-0.034204 linfΔ=7.000000 ‖∇‖=2.883997e-02\n",
      "EPS=7  orig_sim=0.8251 adv_sim=-0.0600 loss_before=0.174931 loss_after=1.059959 linf=6.999596 l2=33.532276 success=1 note=\n",
      "[attack] step 1/1000 loss=0.890780 sim=0.101420 linfΔ=7.314466 ‖∇‖=2.953009e-02\n",
      "[attack] step 1/1000 loss=1.017786 sim=-0.024338 linfΔ=7.885290 ‖∇‖=2.454208e-02\n",
      "[attack] step 1/1000 loss=0.768245 sim=0.224000 linfΔ=7.927049 ‖∇‖=2.881225e-02\n",
      "EPS=8  orig_sim=0.8251 adv_sim=-0.0243 loss_before=0.174931 loss_after=1.024338 linf=7.885290 l2=40.717300 success=1 note=\n",
      "[attack] step 1/1000 loss=1.111833 sim=-0.118898 linfΔ=8.919034 ‖∇‖=2.369351e-02\n",
      "[attack] step 1/1000 loss=1.115594 sim=-0.123067 linfΔ=8.966794 ‖∇‖=2.477573e-02\n",
      "[attack] step 1/1000 loss=0.817037 sim=0.175734 linfΔ=8.828292 ‖∇‖=2.374242e-02\n",
      "EPS=9  orig_sim=0.8251 adv_sim=-0.1231 loss_before=0.174931 loss_after=1.123067 linf=8.966794 l2=40.302063 success=1 note=\n",
      "[attack] step 1/1000 loss=0.899404 sim=0.092913 linfΔ=9.686658 ‖∇‖=2.303885e-02\n",
      "[attack] step 1/1000 loss=1.092782 sim=-0.099991 linfΔ=9.842220 ‖∇‖=2.156681e-02\n",
      "[attack] step 1/1000 loss=0.833075 sim=0.159810 linfΔ=9.692466 ‖∇‖=2.119426e-02\n",
      "EPS=10  orig_sim=0.8251 adv_sim=-0.1000 loss_before=0.174931 loss_after=1.099991 linf=9.842220 l2=46.208973 success=1 note=\n",
      "-------------------------------------------------------------\n",
      "\n",
      "All done. Results saved to attack_results_WESAD_New.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "attack_harness_wesad_full.py\n",
    "\n",
    "Projected-PGD attack on TEXT embedding for WESAD with semantic interpretations.\n",
    "Goals:\n",
    "- High original similarity (orig_sim)\n",
    "- Lower adversarial similarity (adv_sim)\n",
    "- Loss after attack > loss before\n",
    "\n",
    "Features:\n",
    "- Works with HuggingFace transformers if installed; otherwise uses a hashing fallback.\n",
    "- Normalizes embeddings for stable cosine similarity.\n",
    "- PGD uses ε-scaled step size and random start within ε-ball.\n",
    "- Selects best restart by (1) lowest adv_sim, then (2) largest (loss_after - loss_before).\n",
    "- Writes a CSV of results with diagnostics.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import importlib\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------- CONFIG -------------------------\n",
    "EMBEDDING_DIM = 64\n",
    "MARGIN = 0.5\n",
    "TEXT_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "# ---- WESAD settings ----\n",
    "TEXT_COLUMN_NAME = \"semantic_interpretation\"\n",
    "ACTIVITY_COLUMN_NAME = \"label_name\"   # e.g., baseline / stress / amusement\n",
    "\n",
    "# Use 6-D sensors: chest + wrist accelerometer\n",
    "SENSOR_COLUMNS = [\n",
    "    \"chest_acc_x\", \"chest_acc_y\", \"chest_acc_z\",\n",
    "    \"wrist_acc_x\", \"wrist_acc_y\", \"wrist_acc_z\",\n",
    "]\n",
    "SENSOR_FEATURES_COUNT = len(SENSOR_COLUMNS)\n",
    "\n",
    "# Paths\n",
    "SENSOR_MODEL_PATH = \"sensor_encoder_wesad.pth\"\n",
    "TEXT_MODEL_PATH = \"text_encoder_wesad.pth\"\n",
    "DATA_FILE = \"./data/WESAD_with_semantic_interpretation.csv\"\n",
    "\n",
    "# Attack defaults\n",
    "DEFAULT_ALPHA = 0.005                  # per-iteration step size\n",
    "EPSILON_SWEEP = [0.5, 0.6, 0.7, 0.8, 0.9, 1,2,3,4,5,6,7,8,9,10]\n",
    "DEFAULT_STEPS = 1000\n",
    "MODE = \"linf\"                         # \"linf\" or \"l2\"\n",
    "RANDOM_RESTARTS = 3\n",
    "DBG_INTERVAL = 50\n",
    "EARLY_STOP = True\n",
    "\n",
    "TARGET_INDICES = [0,  4000]\n",
    "OUTPUT_CSV = \"attack_results_WESAD_New.csv\"\n",
    "SEED = 0\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ------------------------- HELPERS & TEXT ENCODERS -------------------------\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def _transformers_available():\n",
    "    return importlib.util.find_spec(\"transformers\") is not None\n",
    "\n",
    "class HFTextEncoder(nn.Module):\n",
    "    \"\"\"Uses HuggingFace transformer + trainable projection.\"\"\"\n",
    "    def __init__(self, model_name, output_dim, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        from transformers import AutoTokenizer, AutoModel\n",
    "        self.device = torch.device(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.projection = nn.Linear(self.model.config.hidden_size, output_dim).to(self.device)\n",
    "\n",
    "    def forward(self, texts: List[str]):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        enc = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(self.projection.weight.device) for k, v in enc.items()}\n",
    "        out = self.model(**enc)\n",
    "        pooled = out.last_hidden_state.mean(dim=1)  # (B, H)\n",
    "        return self.projection(pooled)              # (B, D)\n",
    "\n",
    "class HashingTextEncoder(nn.Module):\n",
    "    \"\"\"Dependency-free fallback: simple hashing BoW + projection (keeps gradients).\"\"\"\n",
    "    def __init__(self, output_dim, hash_dim=2048, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.hash_dim = hash_dim\n",
    "        self.projection = nn.Linear(hash_dim, output_dim)\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tokenize(s: str):\n",
    "        return s.lower().split()\n",
    "\n",
    "    def _hash_bow(self, texts):\n",
    "        bows = []\n",
    "        for s in texts:\n",
    "            vec = torch.zeros(self.hash_dim, dtype=torch.float32)\n",
    "            for tok in self._tokenize(s):\n",
    "                idx = (hash(tok) % self.hash_dim)\n",
    "                vec[idx] += 1.0\n",
    "            n = torch.norm(vec, p=2)\n",
    "            if n > 0:\n",
    "                vec = vec / n\n",
    "            bows.append(vec)\n",
    "        return torch.stack(bows, dim=0)\n",
    "\n",
    "    def forward(self, texts: List[str]):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        bows = self._hash_bow(texts).to(self.projection.weight.device)\n",
    "        return self.projection(bows)\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    \"\"\"Wrapper that uses HF if available, else hashing fallback.\"\"\"\n",
    "    def __init__(self, model_name, output_dim, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        if _transformers_available():\n",
    "            print(\"[INFO] Using HuggingFace transformers for TextEncoder.\")\n",
    "            self.impl = HFTextEncoder(model_name, output_dim, device=device)\n",
    "        else:\n",
    "            print(\"[WARN] transformers not found; using hashing-based fallback TextEncoder.\")\n",
    "            self.impl = HashingTextEncoder(output_dim, device=device)\n",
    "\n",
    "    def forward(self, texts: List[str]):\n",
    "        return self.impl(texts)\n",
    "\n",
    "# ------------------------- SENSOR MODEL -------------------------\n",
    "class SensorEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# ------------------------- LOSS & UTILS -------------------------\n",
    "class ContrastiveSimilarityLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Normalized contrastive-style loss:\n",
    "      positive (label=1): 1 - cos(z1,z2)\n",
    "      negative (label=0): max(0, cos(z1,z2) - margin)\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        o1 = F.normalize(output1, p=2, dim=1, eps=1e-8)\n",
    "        o2 = F.normalize(output2, p=2, dim=1, eps=1e-8)\n",
    "        sim = F.cosine_similarity(o1, o2, dim=1, eps=1e-8)\n",
    "        if label.dim() > 1:\n",
    "            label = label.view(-1)\n",
    "        loss_pos = label * (1.0 - sim)\n",
    "        zero = torch.zeros_like(sim)\n",
    "        loss_neg = (1.0 - label) * torch.max(zero, sim - self.margin)\n",
    "        return torch.mean(loss_pos + loss_neg)\n",
    "\n",
    "def l2_project(eta, epsilon):\n",
    "    flat = eta.view(eta.size(0), -1)\n",
    "    norms = torch.norm(flat, p=2, dim=1, keepdim=True).clamp(min=1e-12)\n",
    "    factor = torch.clamp(epsilon / norms, max=1.0)\n",
    "    return (flat * factor).view_as(eta)\n",
    "\n",
    "def compute_norms(perturbation):\n",
    "    p = perturbation.detach().cpu()\n",
    "    linf = p.view(p.size(0), -1).abs().amax(dim=1).mean().item()\n",
    "    l2 = torch.norm(p.view(p.size(0), -1), p=2, dim=1).mean().item()\n",
    "    return linf, l2\n",
    "\n",
    "# ------------------------- ATTACK (PGD on text embedding) -------------------------\n",
    "def pgd_projected_attack(\n",
    "    sensor_encoder, text_encoder, criterion,\n",
    "    x_s, text_str, label,\n",
    "    alpha, epsilon, steps, device,\n",
    "    mode=\"linf\", dbg_interval=50, early_stop=True,\n",
    "    random_start=True\n",
    "):\n",
    "    device = torch.device(device)\n",
    "    x_s = x_s.unsqueeze(0).to(device)                     # (1, F)\n",
    "    label = torch.tensor([label], dtype=torch.float32).to(device)\n",
    "\n",
    "    sensor_encoder.eval()\n",
    "    text_encoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_s = sensor_encoder(x_s)\n",
    "        z_s = F.normalize(z_s, p=2, dim=1, eps=1e-8)\n",
    "        z_t_orig = text_encoder([text_str])\n",
    "        z_t_orig = F.normalize(z_t_orig, p=2, dim=1, eps=1e-8)\n",
    "        loss_before = float(criterion(z_s, z_t_orig, label).item())\n",
    "        orig_sim = float(F.cosine_similarity(z_s, z_t_orig, dim=1).item())\n",
    "\n",
    "    # If already below margin, nothing to do\n",
    "    if orig_sim < MARGIN:\n",
    "        return {\n",
    "            \"orig_sim\": orig_sim, \"adv_sim\": orig_sim,\n",
    "            \"loss_before\": loss_before, \"loss_after\": loss_before,\n",
    "            \"linf\": 0.0, \"l2\": 0.0, \"steps\": 0, \"orig_below_margin\": True\n",
    "        }\n",
    "\n",
    "    # Attack variable around the base text embedding\n",
    "    z_t_base = z_t_orig.detach().clone().to(device)       # (1, D)\n",
    "    z_t_adv  = z_t_base.clone().detach()\n",
    "\n",
    "    # Random start within epsilon-ball so larger ε explores more\n",
    "    if random_start and epsilon > 0:\n",
    "        if mode == \"linf\":\n",
    "            noise = torch.empty_like(z_t_adv).uniform_(-epsilon, epsilon)\n",
    "        else:\n",
    "            noise = torch.randn_like(z_t_adv)\n",
    "            n = torch.norm(noise.view(noise.size(0), -1), p=2, dim=1, keepdim=True).clamp(min=1e-12)\n",
    "            noise = (noise / n) * epsilon * torch.rand_like(n)  # radius in [0, ε]\n",
    "            noise = noise.view_as(z_t_adv)\n",
    "        z_t_adv = (z_t_adv + noise).detach()\n",
    "\n",
    "    z_t_adv.requires_grad_(True)\n",
    "\n",
    "    # Scale step by ε (bounded)\n",
    "    step_size = max(1e-6, float(alpha) * (float(epsilon) if epsilon > 0 else 1.0))\n",
    "    if epsilon > 0:\n",
    "        step_size = min(step_size, float(epsilon))\n",
    "\n",
    "    for step in range(steps):\n",
    "        if z_t_adv.grad is not None:\n",
    "            z_t_adv.grad.zero_()\n",
    "\n",
    "        loss = criterion(z_s, z_t_adv, label)   # normalized inside\n",
    "        # gradient ascent to increase loss (reduce similarity for positive pairs)\n",
    "        loss.backward()\n",
    "        grad = z_t_adv.grad.data\n",
    "\n",
    "        if mode == \"linf\":\n",
    "            step_vec = step_size * torch.sign(grad)\n",
    "        else:\n",
    "            g = grad.view(grad.size(0), -1)\n",
    "            g_norm = torch.norm(g, p=2, dim=1, keepdim=True).clamp(min=1e-12)\n",
    "            step_vec = (step_size * (g / g_norm)).view_as(grad)\n",
    "\n",
    "        z_t_adv.data = z_t_adv.data + step_vec\n",
    "\n",
    "        # Project back to ε-ball\n",
    "        eta = z_t_adv.data - z_t_base.data\n",
    "        if mode == \"linf\":\n",
    "            eta = torch.clamp(eta, -epsilon, epsilon)\n",
    "        else:\n",
    "            eta = l2_project(eta, epsilon)\n",
    "        z_t_adv.data = z_t_base.data + eta\n",
    "\n",
    "        # Diagnostics\n",
    "        if dbg_interval and (step % dbg_interval == 0 or step == steps - 1):\n",
    "            with torch.no_grad():\n",
    "                cur_eta = (z_t_adv.data - z_t_base.data).detach().cpu()\n",
    "                linf_now = cur_eta.abs().amax().item()\n",
    "                grad_norm = torch.norm(grad.view(grad.size(0), -1), p=2, dim=1).mean().item()\n",
    "                sim_now = float(F.cosine_similarity(z_s, F.normalize(z_t_adv, p=2, dim=1), dim=1).item())\n",
    "                print(f\"[attack] step {step+1}/{steps} loss={loss.item():.6f} sim={sim_now:.6f} linfΔ={linf_now:.6f} ‖∇‖={grad_norm:.6e}\")\n",
    "\n",
    "        if early_stop:\n",
    "            with torch.no_grad():\n",
    "                sim_val = float(F.cosine_similarity(z_s, F.normalize(z_t_adv, p=2, dim=1), dim=1).item())\n",
    "            if sim_val < MARGIN:\n",
    "                perturbation = (z_t_adv.detach() - z_t_base.detach()).cpu()\n",
    "                linf_val, l2_val = compute_norms(perturbation)\n",
    "                loss_after = float(criterion(z_s, z_t_adv, label).item())\n",
    "                return {\n",
    "                    \"orig_sim\": orig_sim, \"adv_sim\": sim_val,\n",
    "                    \"loss_before\": loss_before, \"loss_after\": loss_after,\n",
    "                    \"linf\": linf_val, \"l2\": l2_val,\n",
    "                    \"steps\": step + 1, \"orig_below_margin\": False\n",
    "                }\n",
    "\n",
    "    # End of iterations\n",
    "    with torch.no_grad():\n",
    "        final_sim = float(F.cosine_similarity(z_s, F.normalize(z_t_adv, p=2, dim=1), dim=1).item())\n",
    "        loss_after = float(criterion(z_s, z_t_adv, label).item())\n",
    "        perturbation = (z_t_adv.detach() - z_t_base.detach()).cpu()\n",
    "        linf_val, l2_val = compute_norms(perturbation)\n",
    "\n",
    "    return {\n",
    "        \"orig_sim\": orig_sim, \"adv_sim\": final_sim,\n",
    "        \"loss_before\": loss_before, \"loss_after\": loss_after,\n",
    "        \"linf\": linf_val, \"l2\": l2_val,\n",
    "        \"steps\": steps, \"orig_below_margin\": False\n",
    "    }\n",
    "\n",
    "# ------------------------- RUNNER (CSV) -------------------------\n",
    "def run_and_save(\n",
    "    sensor_path=SENSOR_MODEL_PATH,\n",
    "    text_path=TEXT_MODEL_PATH,\n",
    "    data_file=DATA_FILE,\n",
    "    target_indices=TARGET_INDICES,\n",
    "    eps_sweep=EPSILON_SWEEP,\n",
    "    alpha=DEFAULT_ALPHA,\n",
    "    steps=DEFAULT_STEPS,\n",
    "    mode=MODE,\n",
    "    restarts=RANDOM_RESTARTS,\n",
    "    dbg_interval=DBG_INTERVAL,\n",
    "    output_csv=OUTPUT_CSV,\n",
    "    device=DEVICE\n",
    "):\n",
    "    set_seed(SEED)\n",
    "    device = torch.device(device)\n",
    "    print(f\"Device: {device}\\n\")\n",
    "\n",
    "    # Models\n",
    "    try:\n",
    "        sensor_encoder = SensorEncoder(SENSOR_FEATURES_COUNT, EMBEDDING_DIM).to(device)\n",
    "        if os.path.exists(sensor_path):\n",
    "            try:\n",
    "                sensor_encoder.load_state_dict(torch.load(sensor_path, map_location=device))\n",
    "                print(\"[INFO] Loaded sensor encoder weights.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Could not load sensor state_dict cleanly: {e}. Using fresh sensor encoder.\")\n",
    "        else:\n",
    "            print(\"[WARN] sensor model checkpoint not found; using random-initialized sensor encoder.\")\n",
    "\n",
    "        text_encoder = TextEncoder(TEXT_MODEL_NAME, EMBEDDING_DIM, device=str(device)).to(device)\n",
    "        # Try to load projection weights if a checkpoint exists\n",
    "        if os.path.exists(text_path):\n",
    "            try:\n",
    "                ckpt = torch.load(text_path, map_location=device)\n",
    "                if isinstance(text_encoder.impl, HFTextEncoder):\n",
    "                    if isinstance(ckpt, dict) and (\"projection.weight\" in ckpt or \"projection.bias\" in ckpt):\n",
    "                        proj_sd = {k.replace(\"projection.\", \"\"): v for k, v in ckpt.items() if k.startswith(\"projection.\")}\n",
    "                        text_encoder.impl.projection.load_state_dict(proj_sd, strict=False)\n",
    "                        print(\"[INFO] Loaded text encoder projection weights (strict=False).\")\n",
    "                else:\n",
    "                    try:\n",
    "                        text_encoder.impl.load_state_dict(ckpt, strict=False)\n",
    "                        print(\"[INFO] Loaded fallback text encoder checkpoint (strict=False).\")\n",
    "                    except Exception:\n",
    "                        print(\"[WARN] Could not load checkpoint into fallback encoder.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] could not load text checkpoint: {e}. Proceeding with base encoder.\")\n",
    "        else:\n",
    "            print(\"[INFO] No text checkpoint found; using base text encoder (HF or fallback).\")\n",
    "\n",
    "        criterion = ContrastiveSimilarityLoss(margin=MARGIN)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] loading models: {e}\")\n",
    "        return\n",
    "\n",
    "    # Data\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] loading CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    for c in SENSOR_COLUMNS:\n",
    "        if c not in df.columns:\n",
    "            print(f\"[ERROR] Missing required WESAD column: {c}\")\n",
    "            return\n",
    "    if TEXT_COLUMN_NAME not in df.columns:\n",
    "        print(f\"[ERROR] Missing text column: {TEXT_COLUMN_NAME}\")\n",
    "        return\n",
    "    if ACTIVITY_COLUMN_NAME not in df.columns:\n",
    "        print(f\"[ERROR] Missing activity column: {ACTIVITY_COLUMN_NAME}\")\n",
    "        return\n",
    "\n",
    "    sensor_values = df[SENSOR_COLUMNS].values\n",
    "    texts = df[TEXT_COLUMN_NAME].astype(str).tolist()\n",
    "\n",
    "    header = [\n",
    "        \"index\", \"activity\", \"epsilon\", \"alpha\", \"steps\", \"mode\", \"restarts\",\n",
    "        \"orig_sim\", \"adv_sim\", \"loss_before\", \"loss_after\",\n",
    "        \"linf\", \"l2\", \"pgd_steps\", \"success\", \"note\"\n",
    "    ]\n",
    "\n",
    "    with open(output_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for idx in target_indices:\n",
    "            if idx < 0 or idx >= len(df):\n",
    "                print(f\"[WARN] index {idx} out of range, skipping\")\n",
    "                continue\n",
    "\n",
    "            x_s = torch.tensor(sensor_values[idx], dtype=torch.float32)\n",
    "            text_str = texts[idx]\n",
    "            label = 1.0  # positive pair\n",
    "            activity = df[ACTIVITY_COLUMN_NAME].iloc[idx]\n",
    "\n",
    "            print(\"-------------------------------------------------------------\")\n",
    "            print(f\"ATTACK SAMPLE index={idx} activity={activity}\")\n",
    "            print(f\"text preview: '{text_str[:120]}...'\")\n",
    "            print(\"-------------------------------------------------------------\")\n",
    "\n",
    "            for eps in eps_sweep:\n",
    "                best_result = None\n",
    "                note = \"\"\n",
    "                for restart_id in range(restarts):\n",
    "                    res = pgd_projected_attack(\n",
    "                        sensor_encoder, text_encoder, criterion,\n",
    "                        x_s, text_str, label,\n",
    "                        alpha, eps, steps, device,\n",
    "                        mode=mode, dbg_interval=dbg_interval, early_stop=EARLY_STOP,\n",
    "                        random_start=True,\n",
    "                    )\n",
    "\n",
    "                    # Primary: minimize adv_sim; Secondary: maximize loss increase\n",
    "                    if (best_result is None\n",
    "                        or (res[\"adv_sim\"] < best_result[\"adv_sim\"])\n",
    "                        or (math.isclose(res[\"adv_sim\"], best_result[\"adv_sim\"])\n",
    "                            and (res[\"loss_after\"] - res[\"loss_before\"]) >\n",
    "                                (best_result[\"loss_after\"] - best_result[\"loss_before\"]))):\n",
    "                        best_result = res\n",
    "\n",
    "                success = int(best_result[\"adv_sim\"] < MARGIN)\n",
    "                if best_result.get(\"orig_below_margin\", False):\n",
    "                    note = \"orig_sim_below_margin\"\n",
    "                elif best_result[\"loss_after\"] <= best_result[\"loss_before\"]:\n",
    "                    note = \"loss_not_increased\"\n",
    "\n",
    "                row = [\n",
    "                    idx, activity, eps, alpha, steps, mode, restarts,\n",
    "                    round(best_result[\"orig_sim\"], 6),\n",
    "                    round(best_result[\"adv_sim\"], 6),\n",
    "                    round(best_result[\"loss_before\"], 6),\n",
    "                    round(best_result[\"loss_after\"], 6),\n",
    "                    round(best_result[\"linf\"], 6),\n",
    "                    round(best_result[\"l2\"], 6),\n",
    "                    best_result[\"steps\"],\n",
    "                    success,\n",
    "                    note\n",
    "                ]\n",
    "                writer.writerow(row)\n",
    "                f.flush()\n",
    "                print(f\"EPS={eps}  orig_sim={row[7]:.4f} adv_sim={row[8]:.4f} \"\n",
    "                      f\"loss_before={row[9]:.6f} loss_after={row[10]:.6f} \"\n",
    "                      f\"linf={row[11]:.6f} l2={row[12]:.6f} success={row[14]} note={note}\")\n",
    "            print(\"-------------------------------------------------------------\\n\")\n",
    "\n",
    "    print(f\"All done. Results saved to {output_csv}\")\n",
    "\n",
    "# ------------------------- ENTRYPOINT -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"[ERROR] Data file not found: {DATA_FILE}\")\n",
    "        print(\"Update DATA_FILE and rerun.\")\n",
    "        sys.exit(1)\n",
    "    run_and_save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
